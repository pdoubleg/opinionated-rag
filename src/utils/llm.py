"""
Purpose:
    Interact with the OpenAI API.
    Provide supporting prompt engineering functions.
"""

import base64
from pdf2image import convert_from_path
from io import BytesIO
from IPython.display import display, HTML
import json
import sys
from urllib.parse import urlparse
from dotenv import load_dotenv
import os
from typing import Any, Dict, List
import openai
from openai.types.images_response import ImagesResponse
import requests
import tiktoken
import re
from datetime import datetime

from src.types import TurboTool

# load .env file
load_dotenv()

assert os.environ.get("OPENAI_API_KEY")

# get openai api key
openai.api_key = os.environ.get("OPENAI_API_KEY")

# ------------------ helpers ------------------


def safe_get(data, dot_chained_keys):
    """
    {'a': {'b': [{'c': 1}]}}
    safe_get(data, 'a.b.0.c') -> 1
    """
    keys = dot_chained_keys.split(".")
    for key in keys:
        try:
            if isinstance(data, list):
                data = data[int(key)]
            else:
                data = data[key]
        except (KeyError, TypeError, IndexError):
            return None
    return data


def response_parser(response: Dict[str, Any]):
    return safe_get(response, "choices.0.message.content")


def is_url(image_path: str) -> bool:
    """
    Check if the given string is a valid URL.

    Args:
        image_path (str): The string to check.

    Returns:
        bool: True if the string is a valid URL, False otherwise.
    """
    try:
        result = urlparse(image_path)
        return all([result.scheme, result.netloc])
    except ValueError:
        return False

def encode_image_to_base64(image_path: str) -> str:
    """
    Encode a local image file to a base64 string.

    Args:
        image_path (str): The path to the image file.

    Returns:
        str: The base64 encoded string of the image.
    """
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


# ------------------ content generators ------------------


def prompt(
    prompt: str,
    model: str = "gpt-4-1106-preview",
    instructions: str = "You are a helpful assistant.",
) -> str:
    """
    Generate a response from a prompt using the OpenAI API.
    """
    response = openai.chat.completions.create(
        model=model,
        messages=[
            {
                "role": "system",
                "content": instructions,  # Added instructions as a system message
            },
            {
                "role": "user",
                "content": prompt,
            },
        ],
    )

    return response_parser(response.model_dump())


def prompt_func(
    prompt: str,
    turbo_tools: List[TurboTool],
    model: str = "gpt-4-1106-preview",
    instructions: str = "You are a helpful assistant.",
) -> str:
    """
    Generate a response from a prompt using the OpenAI API.
    Force function calls to the provided turbo tools.

    :param prompt: The prompt to send to the model.
    :param turbo_tools: List of TurboTool objects each containing the tool's name, configuration, and function.
    :param model: The model version to use, default is 'gpt-4-1106-preview'.
    :return: The response generated by the model.
    """

    messages = [{"role": "user", "content": prompt}]
    tools = [turbo_tool.config for turbo_tool in turbo_tools]

    tool_choice = (
        "auto"
        if len(turbo_tools) > 1
        else {"type": "function", "function": {"name": turbo_tools[0].name}}
    )

    messages.insert(
        0, {"role": "system", "content": instructions}
    )  # Insert instructions as the first system message
    response = openai.chat.completions.create(
        model=model, messages=messages, tools=tools, tool_choice=tool_choice
    )

    response_message = response.choices[0].message
    tool_calls = response_message.tool_calls

    func_responses = []

    if tool_calls:
        messages.append(response_message)

        for tool_call in tool_calls:
            for turbo_tool in turbo_tools:
                if tool_call.function.name == turbo_tool.name:
                    function_response = turbo_tool.function(
                        **json.loads(tool_call.function.arguments)
                    )

                    func_responses.append(function_response)

                    message_to_append = {
                        "tool_call_id": tool_call.id,
                        "role": "tool",
                        "name": turbo_tool.name,
                        "content": function_response,
                    }
                    messages.append(message_to_append)
                    break

    return func_responses


def prompt_json_response(
    prompt: str,
    model: str = "gpt-4-1106-preview",
    instructions: str = "You are a helpful assistant.",
) -> str:
    """
    Generate a response from a prompt using the OpenAI API.

    Example:
        res = llm.prompt_json_response(
            f"You're a data innovator. You analyze SQL databases table structure and generate 3 novel insights for your team to reflect on and query.
            Generate insights for this this prompt: {prompt}.
            Format your insights in JSON format. Respond in this json format [{{insight, sql, actionable_business_value}}, ...]",
        )
    """

    if not openai.api_key:
        sys.exit(
            """
ERORR: OpenAI API key not found. Please export your key to OPENAI_API_KEY
Example bash command:
    export OPENAI_API_KEY=<your openai apikey>
            """
        )

    response = openai.chat.completions.create(
        model=model,
        messages=[
            {
                "role": "system",
                "content": instructions,  # Added instructions as a system message
            },
            {
                "role": "user",
                "content": prompt,
            },
        ],
        response_format={"type": "json_object"},
    )

    return response_parser(response.model_dump())


def prompt_multi_image_input(
    prompt: str,
    image_paths: List[str],
    max_tokens: int = 500,
    model: str = "gpt-4o",
) -> str:
    """
    Processes a list of images using GPT-4 with vision capabilities.
    Handles both web URLs and local file paths for images.

    Args:
        prompt (str): The text prompt to accompany the images.
        image_paths (List[str]): A list of URLs or local paths for the images.
        max_tokens (int): Maximum number of tokens to use in the API call.

    Returns:
        str: The response from the API call.
    """
    # Construct the messages payload with images
    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
            ] + [
                {"type": "image_url", "image_url": {"url": path} if is_url(path) else f"data:image/jpeg;base64,{encode_image_to_base64(path)}"}
                for path in image_paths
            ],
        }
    ]

    response = openai.chat.completions.create(
        model=model,
        messages=messages,
        max_tokens=max_tokens,
    )
    return response_parser(response.model_dump())


def prompt_one_to_many_image_input(
    prompt: str,
    base_img_path: str, 
    comp_image_paths: List[str],
    max_tokens: int = 520,
    model: str = "gpt-4-vision-preview",
) -> str:
    """
    Compares a base image against a list of comparison images using GPT-4 with vision capabilities.
    Handles both web URLs and local file paths for images.

    Args:
        base_img_path (str): The URL or local path of the base image to compare against.
        comp_image_paths (List[str]): A list of URLs or local paths for the comparison images.
        max_tokens (int): Maximum number of tokens to use in the API call.

    Returns:
        str: The response from the API call.
    """
    # Prepare the base image
    if is_url(base_img_path):
        base_img_content = {"type": "image_url", "image_url": {"url": base_img_path}}
    else:
        base_img_content = {"type": "image_url", "image_url": f"data:image/jpeg;base64,{encode_image_to_base64(base_img_path)}"}

    # Construct the messages payload with the base image
    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": prompt,
                },
                base_img_content
            ],
        }
    ]

    # Dynamically add comparison images to the messages payload
    for comp_image_path in comp_image_paths:
        if is_url(comp_image_path):
            comp_img_content = {"type": "image_url", "image_url": {"url": comp_image_path}}
        else:
            comp_img_content = {"type": "image_url", "image_url": f"data:image/jpeg;base64,{encode_image_to_base64(comp_image_path)}"}

        messages[0]["content"].append(comp_img_content)

    response = openai.chat.completions.create(
        model=model,
        messages=messages,
        max_tokens=max_tokens,
    )
    return response_parser(response.model_dump())


def prompt_image_gen(
    prompt: str,
    openai_key: str = os.getenv("OPENAI_API_KEY"),
    model: str = "dall-e-3", # or 'dall-e-2'
    size_category: str = "square",
    style: str = "vivid", # or 'natural'
    quality: str = "standard",
) -> Dict[str, str]:
    """
    Generate an image from a prompt using the OpenAI API, dynamically save it to a file path based on the prompt and current datetime,
    and return a dictionary with the file path and URL for display purposes.

    Args:
        prompt (str): The prompt to generate the image from.
        openai_key (str): The OpenAI API key.
        model (str, optional): The model to use for image generation. Defaults to "dall-e-3".
        size (str, optional): The size of the generated image. Defaults to "512x512".
        quality (str, optional): The quality of the generated image. Defaults to "standard".

    Returns:
        Dict[str, str]: A dictionary containing the file path and URL of the generated image.
    """   
    d2_size_mapping = {
        "small": "256x256",
        "medium": "512x512",
        "large": "1024x1024",
    }
    d3_size_mapping = {
        "square": "1024x1024",
        "wide": "1792x1024",
        "tall": "1024x1792"
    }
    if model == "dall-e-2":
            size_mapping = d2_size_mapping
    elif model == "dall-e-3":
        size_mapping = d3_size_mapping
    else:
        raise ValueError("Unsupported model. Choose either 'dall-e-2' or 'dall-e-3'.")
    
    # Set the OpenAI API key
    client = openai.OpenAI(
        api_key=openai_key
    )
    
    # Get the size from the mapping
    size = size_mapping.get(size_category, "512x512")

    # Generate the image
    response: ImagesResponse = client.images.generate(
        prompt=prompt,
        model=model,
        n=1,
        quality=quality,
        size=size,
        style=style,
    )

    # Extract the image URL from the response
    image_data = response.data[0]
    image_url = image_data.url

    # Create a sanitized version of the prompt for the file name
    sanitized_prompt = re.sub(r'[^A-Za-z0-9]+', '', prompt)[:8]
    datetime_str = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = "data/dalle_output"
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    file_path = f"{output_dir}/{sanitized_prompt}_{datetime_str}.jpeg"

    # Download and save the image
    with requests.get(image_url, stream=True) as r:
        r.raise_for_status()
        with open(file_path, "wb") as f:
            for chunk in r.iter_content(chunk_size=8192):
                f.write(chunk)
    
    return {"file_path": file_path, "image_url": image_url}



def make_cap_refs(prompt: str, refs: Dict[str, str]) -> str:
    """
    Attach capitalized references to the prompt.
    """

    for key, value in refs.items():
        prompt += f"\n\n{key.upper()}\n\n{value}"

    return prompt


def count_tokens(text: str):
    """
    Count the number of tokens in a string.
    """
    enc = tiktoken.get_encoding("cl100k_base")
    return len(enc.encode(text))


map_model_to_cost_per_1k_tokens = {
    "gpt-4": 0.075,  # ($0.03 Input Tokens + $0.06 Output Tokens) / 2
    "gpt-4-1106-preview": 0.02,  # ($0.01 Input Tokens + $0.03 Output Tokens) / 2
    "gpt-4-1106-vision-preview": 0.02,  # ($0.01 Input Tokens + $0.03 Output Tokens) / 2
    "gpt-3.5-turbo-1106": 0.0015,  # ($0.001 Input Tokens + $0.002 Output Tokens) / 2
}


def estimate_price_and_tokens(text, model="gpt-4"):
    """
    Conservative estimate the price and tokens for a given text.
    """
    # round up to the output tokens
    COST_PER_1k_TOKENS = map_model_to_cost_per_1k_tokens[model]

    tokens = count_tokens(text)

    estimated_cost = (tokens / 1000) * COST_PER_1k_TOKENS

    # round
    estimated_cost = round(estimated_cost, 2)

    return estimated_cost, tokens


def convert_pdf_page_to_base64(pdf_path, page_number):
    """
    Converts a specific page of a PDF to a base64 encoded image.

    Args:
        pdf_path (str): Path to the PDF file.
        page_number (int): The page number to convert (1-indexed).

    Returns:
        str: Base64 encoded string of the image.

    Raises:
        ValueError: If the page number is invalid.
        FileNotFoundError: If the PDF file is not found.
    """
    try:
        # Convert the specific page to an image
        images = convert_from_path(pdf_path, first_page=page_number, last_page=page_number)
        
        if not images:
            raise ValueError(f"Page {page_number} does not exist in the PDF.")
        
        # Get the first (and only) image
        image = images[0]
        
        # Save the image to a bytes buffer
        buffer = BytesIO()
        image.save(buffer, format="PNG")
        
        # Encode the image as base64
        img_str = base64.b64encode(buffer.getvalue()).decode()
        
        return img_str
    
    except FileNotFoundError:
        raise FileNotFoundError(f"The PDF file at {pdf_path} was not found.")
    except Exception as e:
        raise Exception(f"An error occurred: {str(e)}")

def display_pdf_page(pdf_path, page_number):
    """
    Displays a specific page of a PDF as an image in the notebook.

    Args:
        pdf_path (str): Path to the PDF file.
        page_number (int): The page number to display (1-indexed).
    """
    try:
        base64_image = convert_pdf_page_to_base64(pdf_path, page_number)
        display(HTML(f'<img src="data:image/png;base64,{base64_image}" />'))
    except Exception as e:
        print(f"Error displaying PDF page: {str(e)}")
