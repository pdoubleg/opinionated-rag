{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "from IPython.display import Markdown, display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_ROOT_DIR = \"prompts\"\n",
    "TOPIC_DIR = \"cons\"\n",
    "TOPIC = \"Legal Services Department Questions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DEFAULT_PROMPT_ROOT_DIR = \"prompts\"\n",
    "DEFAULT_PROMPT_FILE = \"prompt_concierge.txt\"\n",
    "DEFAULT_TOPIC_DIR = \"cons\"\n",
    "DEFAULT_TOPIC = \"Legal Services Department Inquiries\"\n",
    "\n",
    "\n",
    "def build_omni_prompt(\n",
    "        input_value: str,\n",
    "        topic: str = DEFAULT_TOPIC,\n",
    "        topic_dir: str = DEFAULT_TOPIC_DIR,\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Constructs a complete prompt.\n",
    "\n",
    "        Args:\n",
    "            input_value (str): The user's input question or query.\n",
    "            topic str: The specific topic under which the prompt is categorized.\n",
    "            topic_dir str: The directory associated with the topic.\n",
    "\n",
    "        Returns:\n",
    "            str: A fully constructed prompt ready for use in the autocomplete system.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            prompt_path = Path(DEFAULT_PROMPT_ROOT_DIR) / DEFAULT_PROMPT_FILE\n",
    "            previous_completions_path = (\n",
    "                Path(DEFAULT_PROMPT_ROOT_DIR)\n",
    "                / \"knowledge_bases\"\n",
    "                / topic_dir\n",
    "                / \"previous_completions.json\"\n",
    "            )\n",
    "            domain_knowledge_path = (\n",
    "                Path(DEFAULT_PROMPT_ROOT_DIR)\n",
    "                / \"knowledge_bases\"\n",
    "                / topic_dir\n",
    "                / \"domain_knowledge.txt\"\n",
    "            )\n",
    "\n",
    "            with prompt_path.open(\"r\") as file:\n",
    "                prompt = file.read()\n",
    "\n",
    "            with previous_completions_path.open(\"r\") as file:\n",
    "                previous_completions = file.read()\n",
    "\n",
    "            with domain_knowledge_path.open(\"r\") as file:\n",
    "                domain_knowledge = file.read()\n",
    "\n",
    "            prompt = prompt.replace(\"{{topic}}\", topic)\n",
    "            prompt = prompt.replace(\"{{previous_completions}}\", previous_completions)\n",
    "            prompt = prompt.replace(\"{{domain_knowledge}}\", domain_knowledge)\n",
    "            prompt = prompt.replace(\"{{input_value}}\", input_value)\n",
    "\n",
    "            return prompt\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            raise FileNotFoundError(f\"Required file not found: {e.filename}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"An error occurred while building the prompt: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import fill\n",
    "from typing import List, Optional\n",
    "from typing_extensions import Annotated\n",
    "from annotated_types import Gt, Lt\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "from openai.types.completion_usage import CompletionUsage\n",
    "\n",
    "\n",
    "class Prediction(BaseModel):\n",
    "    \"\"\"Predicted optimal department for a new user query.\"\"\"\n",
    "    \n",
    "    chain_of_thought: str = Field(\n",
    "        description=\"Reasoning behind the prediction based on PREVIOUS_PREDICTIONS and DOMAIN_KNOWLEDGE.\",\n",
    "        exclude=True,\n",
    "    )\n",
    "    predicted_department: str = Field(\n",
    "        ...,\n",
    "        description=\"The predicted department.\",\n",
    "    )\n",
    "    confidence: Annotated[int, Gt(0), Lt(11)] = Field(\n",
    "        ...,\n",
    "        description=\"An integer score from 1-10 indicating prediction confidence.\",\n",
    "    )\n",
    "    \n",
    "    def __str__(self):\n",
    "        wrapped_thought = fill(self.chain_of_thought, width=100)\n",
    "        thought = f\"Thought: {wrapped_thought}\\n\\n\"\n",
    "        thought += f\"Predicted Department: {self.predicted_department}\\n\\n\"\n",
    "        thought += f\"Score: {self.confidence}\\n\"\n",
    "        return thought\n",
    "        \n",
    "        \n",
    "    \n",
    "class MultiPredict(BaseModel):\n",
    "    \"\"\"\n",
    "    Class containing multiple (THREE) predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions (List[Prediction]): The list of predicted departments.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions: List[Prediction] = Field(\n",
    "        ...,\n",
    "        description=\"List of predictions.\",\n",
    "    )\n",
    "    \n",
    "    @model_validator(mode='after')\n",
    "    def sort_predictions_by_confidence(cls, values):\n",
    "        values.predictions = sorted(values.predictions, key=lambda p: p.confidence, reverse=True)\n",
    "        return values       \n",
    "    \n",
    "    @property\n",
    "    def print_preds(self):\n",
    "        output_string = \"\"\n",
    "        for pred in self.predictions:\n",
    "            output_string += str(pred)\n",
    "            output_string += \"\\n------------------------------------------------\\n\\n\"\n",
    "        return output_string\n",
    "\n",
    "\n",
    "class PredictionRequest(BaseModel):\n",
    "    \"\"\"Request model for making predictions.\"\"\"\n",
    "    \n",
    "    user_query: str\n",
    "    ground_truth: Optional[str] = None\n",
    "    model_output: Optional[MultiPredict] = None\n",
    "    token_usage: Optional[CompletionUsage] = None\n",
    "    model_name: Optional[str] = None\n",
    "    run_time: Optional[float] = None\n",
    "    \n",
    "    @property\n",
    "    def cost(self):\n",
    "        return self.token_usage.prompt_tokens * 5 / 1000000 + self.token_usage.completion_tokens * 15 / 1000000\n",
    "    \n",
    "    @property\n",
    "    def prediction_rank(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the rank of the ground truth department in the predictions list.\n",
    "\n",
    "        Returns:\n",
    "            int: The rank of the ground truth department, or 0 if not found.\n",
    "        \"\"\"\n",
    "        if not self.ground_truth or not self.model_output:\n",
    "            return 0\n",
    "        \n",
    "        for rank, prediction in enumerate(self.model_output.predictions, start=1):\n",
    "            if prediction.predicted_department == self.ground_truth:\n",
    "                return rank\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    @property\n",
    "    def cost(self) -> float:\n",
    "        \"\"\"Calculates the cost based on token usage.\n",
    "\n",
    "        Returns:\n",
    "            float: The calculated cost.\n",
    "        \"\"\"\n",
    "        return self.token_usage.prompt_tokens * 5 / 1000000 + self.token_usage.completion_tokens * 15 / 1000000\n",
    "    \n",
    "    @property\n",
    "    def prediction_rank(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the rank of the ground truth department in the predictions list.\n",
    "\n",
    "        Returns:\n",
    "            int: The rank of the ground truth department, or 0 if not found.\n",
    "        \"\"\"\n",
    "        if not self.ground_truth or not self.model_output:\n",
    "            return 0\n",
    "        \n",
    "        for rank, prediction in enumerate(self.model_output.predictions, start=1):\n",
    "            if prediction.predicted_department == self.ground_truth:\n",
    "                return rank\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    @property\n",
    "    def correct_top_one(self) -> bool:\n",
    "        \"\"\"Checks if the ground truth department is the top prediction.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the ground truth department is the top prediction, else False.\n",
    "        \"\"\"\n",
    "        return self.prediction_rank == 1\n",
    "    \n",
    "    @property\n",
    "    def correct_top_two(self) -> bool:\n",
    "        \"\"\"Checks if the ground truth department is within the top two predictions.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the ground truth department is within the top two predictions, else False.\n",
    "        \"\"\"\n",
    "        return self.prediction_rank in [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "import openai\n",
    "import time\n",
    "\n",
    "def get_predictions(input_data: PredictionRequest, topic: str = DEFAULT_TOPIC, topic_dir: str = DEFAULT_TOPIC_DIR) -> MultiPredict:\n",
    "    start_time = time.time()\n",
    "    input_value = input_data.user_query\n",
    "    prompt = build_omni_prompt(\n",
    "        input_value=input_value, topic=topic, topic_dir=topic_dir\n",
    "    )\n",
    "    client = instructor.from_openai(openai.OpenAI())\n",
    "    \n",
    "    response, completion = client.chat.completions.create_with_completion(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                },\n",
    "            ],\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=MultiPredict,\n",
    "        )\n",
    "    # response.sort_predictions_by_confidence()\n",
    "    return PredictionRequest(\n",
    "        user_query=input_data.user_query,\n",
    "        ground_truth=input_data.ground_truth or None,\n",
    "        model_output=response,\n",
    "        token_usage=completion.usage,\n",
    "        model_name=completion.model,\n",
    "        run_time=time.time() - start_time\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I have a complex claim that requires representation in court.\"\n",
    "\n",
    "request = PredictionRequest(\n",
    "    user_query=query,\n",
    "    ground_truth=\"Field Legal\",\n",
    ")\n",
    "\n",
    "response = get_predictions(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009264999999999999"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_query': 'I have a complex claim that requires representation in court.',\n",
       " 'ground_truth': 'Field Legal',\n",
       " 'model_output': {'predictions': [{'predicted_department': 'Field Legal',\n",
       "    'confidence': 10},\n",
       "   {'predicted_department': 'Coverage Team', 'confidence': 8},\n",
       "   {'predicted_department': 'Professional Liability Group', 'confidence': 7}]},\n",
       " 'token_usage': {'completion_tokens': 203,\n",
       "  'prompt_tokens': 1244,\n",
       "  'total_tokens': 1447},\n",
       " 'model_name': 'gpt-4o-2024-05-13',\n",
       " 'run_time': 3.1944096088409424}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The user's request for representation in court suggests litigation. According to the\n",
      "DOMAIN_KNOWLEDGE, the 'Field Legal' department handles all litigation matters. This includes cases\n",
      "referred from the Coverage Team and other departments, indicating their specialization in defending\n",
      "the company in court.\n",
      "\n",
      "Predicted Department: Field Legal\n",
      "\n",
      "Score: 10\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Thought: Since the user mentioned a 'complex claim,' it could involve intricate policy definitions and case\n",
      "law research before heading to litigation. The 'Coverage Team' provides specialized attorneys for\n",
      "such advice on complex claims, making it a relevant department to consider.\n",
      "\n",
      "Predicted Department: Coverage Team\n",
      "\n",
      "Score: 8\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Thought: If the complex claim involves professional liability, such as issues against healthcare, legal, or\n",
      "financial professionals, the 'Professional Liability Group' would be an appropriate choice. They\n",
      "manage claims for malpractice or negligence and provide defense services, which may include\n",
      "litigation.\n",
      "\n",
      "Predicted Department: Professional Liability Group\n",
      "\n",
      "Score: 7\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.model_output.print_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionRequest(user_query='I have a direct report who advised me she is being harassed by a coworker.', ground_truth='Compliance Team', model_output=MultiPredict(predictions=[Prediction(chain_of_thought='The new INPUT_VALUE relates to an employee reporting harassment by a coworker and could involve internal company policies and potential regulatory concerns. Based on the DOMAIN_KNOWLEDGE regarding which department handles internal disputes and regulatory compliance, and given the lack of precise matches in the PREVIOUS_PREDICTIONS, the Compliance Team would be a primary point of contact here.', predicted_department='Compliance Team', confidence=9), Prediction(chain_of_thought=\"Considering the user’s report of workplace harassment, it can also touch upon legal aspects of employment and the potential need for internal investigations. Thus, the Employment Disputes department, which handles issues concerning employees pursuing actions against the company, is relevant here, even though it's generally for actions against the company, they might guide initial steps.\", predicted_department='Employment Disputes', confidence=8), Prediction(chain_of_thought='Given the seriousness of harassment allegations and their potential impact on the company’s working environment, addressing them can also involve regulatory concerns about workplace safety and behavior. Hence, Regulatory Affairs Team could be relevant as they provide guidance on regulatory changes and impacts, ensuring compliance with legal standards and a safe working environment.', predicted_department='Regulatory Affairs Team', confidence=7)]), token_usage=CompletionUsage(completion_tokens=254, prompt_tokens=1251, total_tokens=1505), model_name='gpt-4o-2024-05-13')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# You're a world class legal concierge AI system that predicts optimal queries to COMPLETE the goal of routing them to the correct department.\n",
      "You take a TOPIC, PREVIOUS_COMPLETIONS from past interactions, and DOMAIN_KNOWLEDGE to generate the most likely department and best phrased query based on user INPUT_VALUE.\n",
      "\n",
      "You closely follow GENERATION_RULES to provide the best possible outcomes.\n",
      "\n",
      "## GENERATION_RULES\n",
      "- If the users INPUT_VALUE exists within their PREVIOUS_COMPLETIONS, prefer that completion. Always prefer completions with more hits.\n",
      "- If the users INPUT_VALUE does NOT exist in PREVIOUS_COMPLETIONS, predict completions from DOMAIN_KNOWLEDGE.\n",
      "- Your completions should should always be a valid sentence to be used for future examples.\n",
      "- Be sure to follow the correct format.\n",
      "\n",
      "## TOPIC\n",
      "{{topic}}\n",
      "\n",
      "## PREVIOUS_COMPLETIONS\n",
      "{{previous_completions}}\n",
      "\n",
      "## DOMAIN_KNOWLEDGE\n",
      "{{domain_knowledge}}\n",
      "\n",
      "## Complete the following INPUT_VALUE\n",
      "{{input_value}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = open(f\"{PROMPT_ROOT_DIR}/prompt_concierge.txt\", \"r\").read()\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "def build_omni_complete_prompt(input_value: str, topic: str = \"Legal Services Department Intake\", topic_dir: str = \"cons\") -> str:\n",
    "    \"\"\"\n",
    "    Constructs a complete prompt for the Omni autocomplete system by incorporating various components.\n",
    "\n",
    "    Args:\n",
    "        input_value (str): The user's input question or query.\n",
    "        topic str: The specific topic under which the prompt is categorized. Defaults to \"Legal Services Department Intake\".\n",
    "        topic_dir str: The directory associated with the topic. Defaults to \"cons\".\n",
    "\n",
    "    Returns:\n",
    "        str: A fully constructed prompt ready for use in the autocomplete system.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        prompt_path = Path(PROMPT_ROOT_DIR) / \"prompt_concierge.txt\"\n",
    "        previous_completions_path = Path(PROMPT_ROOT_DIR) / \"knowledge_bases\" / topic_dir / \"previous_completions.json\"\n",
    "        domain_knowledge_path = Path(PROMPT_ROOT_DIR) / \"knowledge_bases\" / topic_dir / \"domain_knowledge.txt\"\n",
    "\n",
    "        with prompt_path.open(\"r\") as file:\n",
    "            prompt = file.read()\n",
    "\n",
    "        with previous_completions_path.open(\"r\") as file:\n",
    "            previous_completions = file.read()\n",
    "\n",
    "        with domain_knowledge_path.open(\"r\") as file:\n",
    "            domain_knowledge = file.read()\n",
    "\n",
    "        prompt = prompt.replace(\"{{topic}}\", topic)\n",
    "        prompt = prompt.replace(\"{{previous_completions}}\", previous_completions)\n",
    "        prompt = prompt.replace(\"{{domain_knowledge}}\", domain_knowledge)\n",
    "        prompt = prompt.replace(\"{{input_value}}\", input_value)\n",
    "\n",
    "        return prompt\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        raise FileNotFoundError(f\"Required file not found: {e.filename}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"An error occurred while building the prompt: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# You're a world class legal concierge AI system that predicts optimal queries to COMPLETE the goal of routing them to the correct department.\n",
      "You take a TOPIC, PREVIOUS_COMPLETIONS from past interactions, and DOMAIN_KNOWLEDGE to generate the most likely department and best phrased query based on user INPUT_VALUE.\n",
      "\n",
      "You closely follow GENERATION_RULES to provide the best possible outcomes.\n",
      "\n",
      "## GENERATION_RULES\n",
      "- If the users INPUT_VALUE exists within their PREVIOUS_COMPLETIONS, prefer that completion. Always prefer completions with more hits.\n",
      "- If the users INPUT_VALUE does NOT exist in PREVIOUS_COMPLETIONS, predict completions from DOMAIN_KNOWLEDGE.\n",
      "- Your completions should should always be a valid sentence to be used for future examples.\n",
      "- Be sure to follow the correct format.\n",
      "\n",
      "## TOPIC\n",
      "Legal Services Department Intake\n",
      "\n",
      "## PREVIOUS_COMPLETIONS\n",
      "[\n",
      "    {\n",
      "        \"input\": \"i need help with a wrongful termination case\",\n",
      "        \"completions\": [\n",
      "            \"Seeking guidance on managing a wrongful termination employment dispute.\"\n",
      "        ],\n",
      "        \"correct_department\": \"Employment Disputes\",\n",
      "        \"hits\": 5\n",
      "    },\n",
      "    {\n",
      "        \"input\": \"can someone assist with a complex insurance claim\",\n",
      "        \"completions\": [\n",
      "            \"Need assistance with a complex insurance claim involving policy definitions and case law research.\"\n",
      "        ],\n",
      "        \"correct_department\": \"Coverage Team\",\n",
      "        \"hits\": 7\n",
      "    },\n",
      "    {\n",
      "        \"input\": \"i have a litigation case that needs attention\",\n",
      "        \"completions\": [\n",
      "            \"Seeking legal support for a litigation case.\"\n",
      "        ],\n",
      "        \"correct_department\": \"Field Legal\",\n",
      "        \"hits\": 6\n",
      "    },\n",
      "    {\n",
      "        \"input\": \"we need to ensure compliance with new regulations\",\n",
      "        \"completions\": [\n",
      "            \"Guidance required for ensuring compliance with new regulations.\"\n",
      "        ],\n",
      "        \"correct_department\": \"Compliance Team\",\n",
      "        \"hits\": 4\n",
      "    },\n",
      "    {\n",
      "        \"input\": \"i suspect insurance fraud in a recent claim\",\n",
      "        \"completions\": [\n",
      "            \"Need assistance with investigating suspected insurance fraud.\"\n",
      "        ],\n",
      "        \"correct_department\": \"Fraud Investigation Unit\",\n",
      "        \"hits\": 8\n",
      "    },\n",
      "    {\n",
      "        \"input\": \"how do we recover funds from a third party responsible for a claim\",\n",
      "        \"completions\": [\n",
      "            \"Seeking guidance on recovering funds from a third party responsible for an insurance claim.\"\n",
      "        ],\n",
      "        \"correct_department\": \"Subrogation Department\",\n",
      "        \"hits\": 3\n",
      "    },\n",
      "    {\n",
      "        \"input\": \"we have a defective product causing harm to customers\",\n",
      "        \"completions\": [\n",
      "            \"Need legal advice on handling claims related to a defective product causing harm.\"\n",
      "        ],\n",
      "        \"correct_department\": \"Product Liability Team\",\n",
      "        \"hits\": 6\n",
      "    },\n",
      "    {\n",
      "        \"input\": \"we need help with an environmental damage claim\",\n",
      "        \"completions\": [\n",
      "            \"Seeking expertise in handling a claim involving environmental damage.\"\n",
      "        ],\n",
      "        \"correct_department\": \"Environmental Claims Unit\",\n",
      "        \"hits\": 5\n",
      "    },\n",
      "    {\n",
      "        \"input\": \"i need legal support for a malpractice claim\",\n",
      "        \"completions\": [\n",
      "            \"Need assistance with managing a malpractice claim.\"\n",
      "        ],\n",
      "        \"correct_department\": \"Professional Liability Group\",\n",
      "        \"hits\": 7\n",
      "    },\n",
      "    {\n",
      "        \"input\": \"we have a construction defect issue that needs legal attention\",\n",
      "        \"completions\": [\n",
      "            \"Seeking legal support for a construction defect claim.\"\n",
      "        ],\n",
      "        \"correct_department\": \"Construction Defects Team\",\n",
      "        \"hits\": 4\n",
      "    },\n",
      "    {\n",
      "        \"input\": \"i need advice on a workers' compensation claim\",\n",
      "        \"completions\": [\n",
      "            \"Need legal advice on managing a workers' compensation claim.\"\n",
      "        ],\n",
      "        \"correct_department\": \"Workers' Compensation Legal Team\",\n",
      "        \"hits\": 6\n",
      "    },\n",
      "    {\n",
      "        \"input\": \"we have an intellectual property dispute\",\n",
      "        \"completions\": [\n",
      "            \"Seeking guidance on handling an intellectual property dispute.\"\n",
      "        ],\n",
      "        \"correct_department\": \"Intellectual Property Group\",\n",
      "        \"hits\": 5\n",
      "    },\n",
      "    {\n",
      "        \"input\": \"we need help with a contractual dispute with a vendor\",\n",
      "        \"completions\": [\n",
      "            \"Need assistance with resolving a contractual dispute with a vendor.\"\n",
      "        ],\n",
      "        \"correct_department\": \"Contractual Disputes Team\",\n",
      "        \"hits\": 7\n",
      "    },\n",
      "    {\n",
      "        \"input\": \"we are planning a merger and need legal support\",\n",
      "        \"completions\": [\n",
      "            \"Seeking legal support for an upcoming merger.\"\n",
      "        ],\n",
      "        \"correct_department\": \"Mergers & Acquisitions Legal Team\",\n",
      "        \"hits\": 4\n",
      "    },\n",
      "    {\n",
      "        \"input\": \"we have a real estate transaction that needs legal advice\",\n",
      "        \"completions\": [\n",
      "            \"Need legal advice on a real estate transaction.\"\n",
      "        ],\n",
      "        \"correct_department\": \"Real Estate Legal Services\",\n",
      "        \"hits\": 6\n",
      "    },\n",
      "    {\n",
      "        \"input\": \"we need help with a bankruptcy case\",\n",
      "        \"completions\": [\n",
      "            \"Seeking guidance on managing a bankruptcy case.\"\n",
      "        ],\n",
      "        \"correct_department\": \"Bankruptcy and Insolvency Team\",\n",
      "        \"hits\": 5\n",
      "    }\n",
      "]\n",
      "\n",
      "## DOMAIN_KNOWLEDGE\n",
      "# Employment Disputes\n",
      "Handles legal issues concerning current or former employees pursuing legal action against the company.\n",
      "Cases include wrongful termination, payment-related disputes, or contractual matters.\n",
      "Does not handle discrimination accusations.\n",
      "\n",
      "# Coverage Team\n",
      "Specialized attorneys providing advice on complex claims.\n",
      "Assist with policy definitions and their application.\n",
      "Conduct case law research.\n",
      "Referrals are only for non-litigated matters.\n",
      "For litigation, refer to Field Legal.\n",
      "\n",
      "# Field Legal\n",
      "Manages all litigation matters.\n",
      "Handles cases referred from the Coverage Team and other departments.\n",
      "Specializes in defending the company in court.\n",
      "\n",
      "# Compliance Team\n",
      "Ensures company adherence to legal standards and regulations.\n",
      "Handles internal audits and regulatory reviews.\n",
      "Provides guidance on compliance-related issues.\n",
      "\n",
      "# Fraud Investigation Unit\n",
      "Investigates suspected insurance fraud cases.\n",
      "Works closely with law enforcement and other agencies.\n",
      "Provides support for both internal and external fraud matters.\n",
      "\n",
      "# Subrogation Department\n",
      "Recovers funds from third parties responsible for insurance claims.\n",
      "Works with other departments to identify subrogation opportunities.\n",
      "Manages legal proceedings related to subrogation.\n",
      "\n",
      "# Product Liability Team\n",
      "Deals with claims related to defective products causing harm or damage.\n",
      "Provides legal advice and defense strategies.\n",
      "Collaborates with product development teams for risk mitigation.\n",
      "\n",
      "# Environmental Claims Unit\n",
      "Handles claims involving environmental damage and pollution.\n",
      "Provides expertise in environmental law and regulations.\n",
      "Works on cleanup cost recovery and liability defense.\n",
      "\n",
      "# Professional Liability Group\n",
      "Manages claims against professionals for malpractice or negligence.\n",
      "Specializes in sectors like healthcare, legal, and financial services.\n",
      "Offers defense and settlement negotiation services.\n",
      "\n",
      "# Construction Defects Team\n",
      "Deals with claims related to construction defects and contractor negligence.\n",
      "Works with engineers and experts for case assessments.\n",
      "Provides litigation and arbitration support.\n",
      "\n",
      "# Workers' Compensation Legal Team\n",
      "Manages claims related to workplace injuries and illnesses.\n",
      "Provides legal advice on workers' compensation laws and settlements.\n",
      "Collaborates with HR and risk management teams.\n",
      "\n",
      "# Intellectual Property Group\n",
      "Handles cases involving IP rights, including patents, trademarks, and copyrights.\n",
      "Provides defense against IP infringement claims.\n",
      "Assists in securing and enforcing the companyâ€™s IP assets.\n",
      "\n",
      "# Contractual Disputes Team\n",
      "Resolves disputes arising from contracts with vendors, partners, and clients.\n",
      "Provides negotiation and litigation support.\n",
      "Advises on contract drafting and risk management.\n",
      "\n",
      "# Mergers & Acquisitions Legal Team\n",
      "Provides legal support for mergers, acquisitions, and divestitures.\n",
      "Conducts due diligence and risk assessments.\n",
      "Handles regulatory approvals and compliance issues.\n",
      "\n",
      "# Real Estate Legal Services\n",
      "Manages legal aspects of property transactions and disputes.\n",
      "Provides advice on leases, acquisitions, and zoning laws.\n",
      "Works with real estate agents and property managers.\n",
      "\n",
      "# Bankruptcy and Insolvency Team\n",
      "Handles cases involving bankruptcies and insolvencies.\n",
      "Provides advice on creditor rights and debt recovery.\n",
      "Manages legal proceedings related to bankruptcy.\n",
      "\n",
      "# Data Privacy and Security Legal Team\n",
      "Ensures compliance with data protection laws and regulations.\n",
      "Manages data breach responses and investigations.\n",
      "Provides guidance on data privacy policies and practices.\n",
      "\n",
      "# Insurance Defense Team\n",
      "Provides defense against claims made under insurance policies.\n",
      "Specializes in liability, property, and casualty insurance claims.\n",
      "Works with claims adjusters and investigators.\n",
      "\n",
      "# Regulatory Affairs Team\n",
      "Manages relationships with regulatory bodies.\n",
      "Ensures compliance with industry regulations.\n",
      "Provides guidance on regulatory changes and impacts.\n",
      "\n",
      "# Employment Benefits Legal Team\n",
      "Handles legal issues related to employee benefits and compensation.\n",
      "Provides advice on retirement plans, health benefits, and compliance.\n",
      "Manages disputes and litigation involving employee benefits.\n",
      "\n",
      "# International Claims Unit\n",
      "Manages claims involving international policies and incidents.\n",
      "Provides expertise in international law and cross-border disputes.\n",
      "Works with global partners and legal teams.\n",
      "\n",
      "# Cybersecurity Legal Team\n",
      "Provides legal support for cybersecurity incidents and breaches.\n",
      "Ensures compliance with cybersecurity regulations.\n",
      "Manages legal aspects of cybersecurity policies and protocols.\n",
      "\n",
      "# Healthcare Liability Team\n",
      "Manages claims against healthcare providers and institutions.\n",
      "Provides defense and settlement negotiation services.\n",
      "Specializes in medical malpractice and healthcare regulations.\n",
      "\n",
      "# Auto Claims Legal Team\n",
      "Handles claims related to auto accidents and vehicle damage.\n",
      "Provides legal advice and defense strategies.\n",
      "Works with claims adjusters and auto repair experts.\n",
      "\n",
      "# Property Damage Legal Team\n",
      "Manages claims involving property damage from natural disasters, accidents, and other incidents.\n",
      "Provides legal support for damage assessments and settlements.\n",
      "Collaborates with claims adjusters and repair contractors.\n",
      "\n",
      "\n",
      "## Complete the following INPUT_VALUE\n",
      "who can help me with a question about pollution damage?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_example = build_omni_complete_prompt(\"who can help me with a question about pollution damage?\")\n",
    "print(prompt_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "def truncate_json_by_tokens(json_string: str, threshold: int, model: str = \"gpt-3.5-turbo\") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Truncates a JSON string into a list of dictionaries based on a token threshold using a specified model.\n",
    "\n",
    "    Args:\n",
    "        json_string (str): The JSON string to be truncated.\n",
    "        threshold (int): The maximum number of tokens allowed in the truncated output.\n",
    "        model (str): The model used to count tokens, default is \"gpt-3.5-turbo\".\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: A list of dictionaries representing the truncated JSON data.\n",
    "    \"\"\"\n",
    "    data = json.loads(json_string)\n",
    "    truncated_data = []\n",
    "    current_tokens = 0\n",
    "\n",
    "    for item in data:\n",
    "        item_string = json.dumps(item, indent=4)\n",
    "        item_tokens = count_tokens(item_string, model)\n",
    "        \n",
    "        if current_tokens + item_tokens > threshold:\n",
    "            break\n",
    "        \n",
    "        truncated_data.append(item)\n",
    "        current_tokens += item_tokens\n",
    "\n",
    "    return truncated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Type, TypeVar\n",
    "from pydantic import BaseModel\n",
    "\n",
    "T = TypeVar('T', bound=BaseModel)\n",
    "\n",
    "\n",
    "def save_models_to_json(models: List[BaseModel], file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves a list of Pydantic models to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        models: A list of Pydantic model instances.\n",
    "        file_path: The path to the JSON file where the data will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'w') as f:\n",
    "            # Convert list of models to list of dictionaries\n",
    "            data = [model.model_dump() for model in models]\n",
    "            json.dump(data, f, indent=4)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Required file not found: {file_path}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"An error occurred while loading the previous completions: {e}\")  \n",
    "        \n",
    "\n",
    "def load_models_from_json(model_class: Type[T], file_path: str) -> List[T]:\n",
    "    \"\"\"\n",
    "    Loads JSON data from a file and converts it into a list of Pydantic models.\n",
    "\n",
    "    Args:\n",
    "        model_class: The Pydantic model class to which the JSON objects will be converted.\n",
    "        file_path: The path to the JSON file from which the data will be loaded.\n",
    "\n",
    "    Returns:\n",
    "        A list of Pydantic model instances.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            models = [model_class.model_validate(item) for item in data]\n",
    "        return models\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Required file not found: {file_path}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"An error occurred while loading the previous completions: {e}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completions_path(prompt_root_dir: str, topic_dir: str) -> str:\n",
    "    return f\"{prompt_root_dir}/knowledge_bases/{topic_dir}/previous_completions.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_path = get_completions_path(PROMPT_ROOT_DIR, \"cons\")\n",
    "\n",
    "previous_comp_models = load_models_from_json(\n",
    "    model_class=AutoCompletion,\n",
    "    file_path=prompt_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class AutoCompletionEntry(BaseModel):\n",
    "    input: str\n",
    "    completions: List[str]\n",
    "    correct_department: str\n",
    "    hits: int = 1\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.model_dump_json(indent=4)\n",
    "    \n",
    "    @property\n",
    "    def token_count(self):\n",
    "        return count_tokens(str(self))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class AutoCompletions(BaseModel):\n",
    "    \"\"\"Auto-completions for a new user query.\"\"\"\n",
    "    \n",
    "    input: str = Field(\n",
    "        ...,\n",
    "        description=\"The user provided INPUT_VALUE.\",\n",
    "    )\n",
    "    completions: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"A list of potential completions based on the GENERATION_RULES.\",\n",
    "    )\n",
    "    correct_department: str = Field(\n",
    "        ...,\n",
    "        description=\"The predicted department based on ALL available information.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List\n",
    "from pydantic import ValidationError\n",
    "\n",
    "def increment_or_create_previous_completions(input: str, completion: str, topic_dir: str) -> List[AutoCompletionEntry]:\n",
    "    \"\"\"\n",
    "    Updates the list of previous completions by incrementing the hit count for existing entries\n",
    "    or creating a new entry if no match is found. The list is then sorted by hits in descending order\n",
    "    and saved back to the file.\n",
    "\n",
    "    Args:\n",
    "        input (str): The user input string to match or add.\n",
    "        completion (str): The completion string associated with the input.\n",
    "        topic_dir (str): The directory name under which the completions file is stored.\n",
    "\n",
    "    Returns:\n",
    "        List[AutoCompletionEntry]: A list of AutoCompletionEntry objects sorted by hits in descending order.\n",
    "    \"\"\"\n",
    "    previous_completions_file = (\n",
    "        f\"{PROMPT_ROOT_DIR}/knowledge_bases/{topic_dir}/previous_completions.json\"\n",
    "    )\n",
    "\n",
    "    # Try to read the previous completions file\n",
    "    try:\n",
    "        with open(previous_completions_file, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "            previous_completions = [AutoCompletionEntry(**item) for item in data]\n",
    "    except (FileNotFoundError, json.JSONDecodeError, ValidationError):\n",
    "        previous_completions = []\n",
    "\n",
    "    # Check for a matching input and completion\n",
    "    matching_case = None\n",
    "    for item in previous_completions:\n",
    "        if item.input.lower() == input.lower():\n",
    "            for existing_completion in item.completions:\n",
    "                if completion.lower() in existing_completion.lower():\n",
    "                    matching_case = item\n",
    "                    break\n",
    "\n",
    "    # Update hits if a match is found, otherwise create a new entry\n",
    "    if matching_case:\n",
    "        matching_case.hits += 1\n",
    "    else:\n",
    "        new_completion = AutoCompletionEntry(input=input, completions=[completion])\n",
    "        previous_completions.append(new_completion)\n",
    "\n",
    "    # Sort completions by hits in descending order\n",
    "    completions_sorted_by_hits = sorted(\n",
    "        previous_completions, key=lambda x: x.hits, reverse=True\n",
    "    )\n",
    "\n",
    "    # Write the updated completions back to the file\n",
    "    with open(previous_completions_file, \"w\") as file:\n",
    "        json.dump([item.model_dump() for item in completions_sorted_by_hits], file, indent=4)\n",
    "\n",
    "    return completions_sorted_by_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "import openai\n",
    "\n",
    "def get_autocompletions(input_data: str, topic: str, topic_dir: str) -> AutoCompletions:\n",
    "\n",
    "    prompt = build_omni_complete_prompt(\n",
    "        input_data, topic=topic, topic_dir=topic_dir\n",
    "    )\n",
    "    client = instructor.from_openai(openai.OpenAI())\n",
    "    \n",
    "    return client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                },\n",
    "            ],\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=AutoCompletions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = 'I need assistance with a legal issue involving a NDA'\n",
    "\n",
    "autocompletions = get_autocompletions(\n",
    "    input_data=input_data, \n",
    "    topic=\"Legal Services Department Intake\", \n",
    "    topic_dir=\"cons\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'I need assistance with a legal issue involving a NDA',\n",
       " 'completions': ['Need assistance with a legal issue involving a non-disclosure agreement (NDA).'],\n",
       " 'correct_department': 'Contractual Disputes Team'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autocompletions.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
